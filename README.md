# Video Sub Translate ðŸŽ™ï¸âž¡ï¸ðŸŒ

**Video Sub Translate** is a speech processing pipeline that takes in video or audio, removes silence, transcribes speech using [Faster-Whisper](https://github.com/guillaumekln/faster-whisper), and prepares the results for translation and subtitle generation (SRT).

Itâ€™s designed to handle real-world media efficiently â€” cutting silence first means less audio to process, faster transcription, and cleaner subtitles.

---

## âœ¨ Features
- ðŸŽ¬ **Video/Audio input** (via [PyDub](https://github.com/jiaaro/pydub))  
- ðŸ”‡ **Silence removal** for faster processing & clean chunks  
- ðŸ§© **SpeechChunk abstraction** â€” each chunk carries its transcription, metadata, and timing offsets  
- âš¡ **GPU-accelerated transcription** (Faster-Whisper on CUDA)  
- ðŸŒ **Dynamic language support** (auto-detect or user-specified)  
- ðŸ“ **Per-chunk text output** for debugging / translation pipelines  
- â±ï¸ **SRT subtitle export** aligned to the original timeline (video-editor ready)  

---

## ðŸ› ï¸ Tech Stack
- **Python 3.10+**
- [PyDub](https://github.com/jiaaro/pydub) â€” audio cutting & silence removal  
- [Faster-Whisper](https://github.com/guillaumekln/faster-whisper) â€” transcription  
- **CUDA + cuDNN** â€” GPU acceleration  
- [GPUtil](https://github.com/anderskm/gputil) â€” GPU checks  

---
## ðŸš€ Architecture Overview
```
flowchart TD
    A[Video/Audio Input]
    B[Silence Removal (PyDub)]
    C[SpeechChunks Created]
    D[Transcription (Faster-Whisper)]
    E[Per-Chunk .txt Files]
    F[Merge with Offsets]
    G[SRT Subtitle Output]
    H[Optional Translation Pipeline]

    A --> B
    B --> C
    C --> D
    D --> E
    D --> F
    F --> G
    E --> H
    H --> G
```
---

## ðŸš€ Usage
1. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

2. Place your media file in the `input/` directory.  

3. Run the main script:
   ```bash
   python main.py
   ```

4. Results:
   - Per-chunk `.txt` files â†’ `output/transcriptions/`  
   - Final `.srt` file â†’ aligned to the original video timeline  

---

## âš¡ Example (console output)

```
ðŸŽ™ï¸ Processing chunk 3/12: chunks/clip_3.wav
   Detected language: en
   [00:01.20s -> 00:04.10s] Hello, how are you?
   [00:04.10s -> 00:07.50s] I'm fine, thanks.
```

---

## ðŸ’¡ Why SpeechChunks?
Silence removal splits long recordings into manageable `SpeechChunk`s.  
Each chunk stores:
- start / end offsets (ms) in the original video,  
- transcription text,  
- source language,  
- file paths for disk output.  

This makes it easy to:
- process efficiently,  
- debug per-chunk results,  
- reassemble accurate subtitles later.  

---

## ðŸ—ï¸ Future Work
- ðŸŒ Automatic translation step (integrate with e.g. MarianMT, DeepL, or OpenAI API)  
- ðŸ—‚ï¸ Project-wide config for transcription options (beam size, temperature, language)  
- ðŸ–¥ï¸ Web UI for uploading media and downloading subtitles  

---

## ðŸš§ Current Status & Next Steps  

### ðŸ”œ Features to Implement
- **Text File Export:** Write transcriptions to disk in a translation-ready format.  
- **Event System:** Introduce hooks/events for modular extension (e.g. monitoring, logging, UI updates).  
- **Translation Pipeline:** Add input/output translation into any supported language.  
- **Subtitle Generation:** Build SRT/Subtitle files with precise timecodes for use in video editors.  
- **Web UI:** Provide a simple, interactive interface for end users.  

---

### ðŸ“Œ Notes on Progress
- The core AI transcription pipeline is **fully functional** and producing highly accurate subtitles.  
- Stress-tested on **challenging, noisy audio** (e.g. old TV shows with poor sound quality).  
- Whisper/Faster-Whisper can handle a wide variety of accents â€” including **UK regional dialects** (yes, even 1980s *Coronation Street*).  
- Debugging is ongoing across the full pipeline, but the results so far are extremely promising.  

---

## ðŸ‘¨â€ðŸ’» About the Developer  
This project was built as part of a portfolio to demonstrate:  
- Persistence and resilience in solving complex technical challenges.  
- Strong problem-solving ability across Python, PyTorch, and CUDA.  
- End-to-end system design, from data preprocessing to AI inference to output formatting.  

> It reflects a commitment to building practical, production-ready AI solutions under real-world constraints.  
